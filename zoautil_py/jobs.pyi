import logging
from _typeshed import Incomplete
from datetime import datetime
from zoautil_py.common import cast_int_optional as cast_int_optional, clean_dataset_name as clean_dataset_name, clean_shell_input as clean_shell_input, parse_universal_arguments as parse_universal_arguments, parse_unknown as parse_unknown, zoau_json_load as zoau_json_load
from zoautil_py.core import call_zoau_library as call_zoau_library
from zoautil_py.core_return_codes import DDLSReturnCodes as DDLSReturnCodes
from zoautil_py.exceptions import DDQueryException as DDQueryException, JobCancelConfirmException as JobCancelConfirmException, JobCancelException as JobCancelException, JobFetchException as JobFetchException, JobPurgeConfirmException as JobPurgeConfirmException, JobPurgeException as JobPurgeException, JobSubmitException as JobSubmitException
from zoautil_py.ztypes import ZOAUResponse as ZOAUResponse

logger: logging.Logger
BASIC_JOB_FIELDS: Incomplete
EXTENDED_JOB_FIELDS: Incomplete

class Job:
    job_id: str
    name: str
    job_class: str
    asid: int
    priority: int
    queue_position: int
    owner: str | None
    program_name: str | None
    return_code: str | None
    status: str | None
    service_class: str | None
    creation_datetime: datetime | None
    job_type: str | None
    execution_time: str | None
    execution_seconds: int | None
    system: str | None
    subsystem: str | None
    origin_node: str | None
    execution_node: str | None
    member_name: str | None
    purged: bool
    def __init__(self, job_id: str, name: str, job_class: str, asid: str | int, priority: str | int, queue_position: str | int, owner: str | None = None, program_name: str | None = None, return_code: str | None = None, status: str | None = None, service_class: str | None = None, creation_datetime: str | datetime | None = None, job_type: str | None = None, execution_time: str | None = None, execution_seconds: str | None = None, system: str | None = None, subsystem: str | None = None, origin_node: str | None = None, execution_node: str | None = None, member_name: str | None = None, purged: bool = False) -> None: ...
    @classmethod
    def from_core_json(cls, job_as_json: dict): ...
    def cancel(self, purge_job: bool = False, confirm_timeout: int = 0): ...
    def purge(self, confirm_timeout: int = 0): ...
    def refresh(self) -> None: ...
    def wait(self, seconds_per_loop: float = 1): ...
    def fetch_extended_fields(self) -> None: ...

def submit_return_job_id(source: str, is_unix: bool = False, **kwargs) -> str: ...
def submit(source: str, is_unix: bool = False, **kwargs) -> Job: ...
def cancel(job_id: str, purge_job: bool = False, confirm_timeout: int = 0, **kwargs) -> None: ...
def purge(job_id: str, confirm_timeout: int = 0, **kwargs) -> None: ...
def list_dds(job_id: str, **kwargs) -> list[dict]: ...
def read_output(job_id: str, stepname: str = "'*'", dd_name: str = '', **kwargs) -> str: ...
def fetch_multiple_as_json(job_id: str | None = None, job_owner: str | None = None, job_name: str | None = None, included_fields: list[str] | None = ..., **kwargs) -> dict: ...
def fetch_multiple(job_id: str | None = None, job_owner: str | None = None, job_name: str | None = None, include_extended: bool = False, **kwargs) -> list[Job]: ...
def exists(job_id: str, **kwargs) -> bool: ...
def fetch(job_id: str | None = None, include_extended: bool = False, **kwargs) -> Job: ...
def fetch_extended_fields(job: Job) -> None: ...
def refresh(job: Job, **kwargs) -> None: ...
